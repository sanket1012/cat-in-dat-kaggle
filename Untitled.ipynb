{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_train = pd.read_csv('../train.csv')\n",
    "df_test = pd.DataFrame()\n",
    "df_test = pd.read_csv('../test.csv')\n",
    "\n",
    "df_train.drop(['id','nom_8','nom_9'], axis=1,inplace=True)\n",
    "df_test.drop(['id','nom_8','nom_9'], axis=1,inplace=True)\n",
    "\n",
    "df_train['bin_3'] = (df_train['bin_3'] =='T').astype(int)\n",
    "df_train['bin_4'] = (df_train['bin_4'] =='Y').astype(int)\n",
    "\n",
    "df_test['bin_3'] = (df_test['bin_3'] =='T').astype(int)\n",
    "df_test['bin_4'] = (df_test['bin_4'] =='Y').astype(int)\n",
    "\n",
    "# train_df = pd.get_dummies(df_train, columns=['nom_0','nom_1','nom_2','nom_3','nom_4','nom_5','nom_6','nom_7','ord_0','ord_1','ord_2','ord_3','ord_4','ord_5','day','month'], drop_first=False, sparse=True)\n",
    "# test_df = pd.get_dummies(df_test, columns=['nom_0','nom_1','nom_2','nom_3','nom_4','nom_5','nom_6','nom_7','ord_0','ord_1','ord_2','ord_3','ord_4','ord_5','day','month'], drop_first=False, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in nom_0 = 3\n",
      "Number of classes in nom_1 = 6\n",
      "Number of classes in nom_2 = 6\n",
      "Number of classes in nom_3 = 6\n",
      "Number of classes in nom_4 = 4\n",
      "Number of classes in nom_5 = 222\n",
      "Number of classes in nom_6 = 522\n",
      "Number of classes in nom_7 = 1220\n",
      "Number of classes in ord_0 = 3\n",
      "Number of classes in ord_1 = 5\n",
      "Number of classes in ord_2 = 6\n",
      "Number of classes in ord_3 = 15\n",
      "Number of classes in ord_4 = 26\n",
      "Number of classes in ord_5 = 192\n",
      "Number of classes in day = 7\n",
      "Number of classes in month = 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def one_hot(train_df,test_df,columns):\n",
    "    \n",
    "    for i,column in enumerate(columns):\n",
    "        Xtrain = train_df[str(column)].T\n",
    "        Xtest = test_df[str(column)].T\n",
    "        \n",
    "        # train_df\n",
    "        lb=LabelBinarizer()\n",
    "        lb.fit(Xtrain)\n",
    "        X_classes = len(lb.classes_)\n",
    "        Xenc = lb.transform(Xtrain)\n",
    "        Xtrain_enc = pd.DataFrame(data = Xenc, columns = lb.classes_)\n",
    "        train_df.drop([str(column)], axis =1, inplace=True)\n",
    "        \n",
    "        # test_df\n",
    "        Xenc = lb.transform(Xtest)\n",
    "        Xtest_enc = pd.DataFrame(data = Xenc, columns = lb.classes_)\n",
    "        test_df.drop([str(column)], axis =1, inplace=True)\n",
    "        \n",
    "        print('Number of classes in '+str(column)+ ' = '+ str(X_classes))\n",
    "        train_df = pd.concat((train_df,Xtrain_enc),axis=1)\n",
    "        test_df = pd.concat((test_df,Xtest_enc),axis=1) \n",
    "    return train_df,test_df\n",
    "\n",
    "train_df , test_df = one_hot(df_train,df_test,['nom_0','nom_1','nom_2','nom_3','nom_4','nom_5','nom_6','nom_7','ord_0','ord_1','ord_2','ord_3','ord_4','ord_5','day','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=300000\n",
      "bin_0=2\n",
      "bin_1=2\n",
      "bin_2=2\n",
      "bin_3=2\n",
      "bin_4=2\n",
      "nom_0=3\n",
      "nom_1=6\n",
      "nom_2=6\n",
      "nom_3=6\n",
      "nom_4=4\n",
      "nom_5=222\n",
      "nom_6=522\n",
      "nom_7=1220\n",
      "nom_8=2215\n",
      "nom_9=11981\n",
      "ord_0=3\n",
      "ord_1=5\n",
      "ord_2=6\n",
      "ord_3=15\n",
      "ord_4=26\n",
      "ord_5=192\n",
      "day=7\n",
      "month=12\n",
      "target=2\n"
     ]
    }
   ],
   "source": [
    "for k, v in df_train.nunique().to_dict().items():\n",
    "    print('{}={}'.format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 2260)\n",
      "(300000, 1)\n",
      "(240000, 2260)\n",
      "(60000, 1)\n",
      "(200000, 2259)\n"
     ]
    }
   ],
   "source": [
    "x=train_df.drop(['target'], axis=1)\n",
    "y=train_df[['target']].copy()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "x_test = np.array(test_df)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1108 08:33:22.288170 12364 deprecation.py:506] From C:\\Users\\sanket.waghmare\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 512)               145920    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 391,137\n",
      "Trainable params: 391,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 240000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "240000/240000 [==============================] - 20s 83us/step - loss: 0.5375 - acc: 0.7328 - val_loss: 0.5278 - val_acc: 0.7377\n",
      "Epoch 2/100\n",
      "240000/240000 [==============================] - 17s 72us/step - loss: 0.5260 - acc: 0.7401 - val_loss: 0.5298 - val_acc: 0.7378\n",
      "Epoch 3/100\n",
      "240000/240000 [==============================] - 18s 76us/step - loss: 0.5210 - acc: 0.7427 - val_loss: 0.5405 - val_acc: 0.7356\n",
      "Epoch 4/100\n",
      "240000/240000 [==============================] - 19s 78us/step - loss: 0.5147 - acc: 0.7468 - val_loss: 0.5339 - val_acc: 0.7342\n",
      "Epoch 5/100\n",
      "240000/240000 [==============================] - 18s 74us/step - loss: 0.5047 - acc: 0.7538 - val_loss: 0.5442 - val_acc: 0.7299\n",
      "Epoch 6/100\n",
      "240000/240000 [==============================] - 18s 76us/step - loss: 0.4898 - acc: 0.7623 - val_loss: 0.5443 - val_acc: 0.7272\n",
      "Epoch 7/100\n",
      "240000/240000 [==============================] - 19s 81us/step - loss: 0.4711 - acc: 0.7757 - val_loss: 0.5625 - val_acc: 0.7090\n",
      "Epoch 8/100\n",
      " 69120/240000 [=======>......................] - ETA: 12s - loss: 0.4368 - acc: 0.7990"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ad2f4b52bfe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=296))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=100, batch_size=256, validation_data=(x_valid,y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-bccdd389f085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "x=train_df.drop(['target'], axis=1)\n",
    "y=train_df[['target']].copy()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "x_train = np.array(x[:int(300000*0.8)])\n",
    "y_train = np.array(y[:int(300000*0.8)])\n",
    "x_valid = np.array(x[int(300000*0.8):])\n",
    "y_valid = np.array(y[int(300000*0.8):])\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "x_test = np.array(test_df)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanket.waghmare\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\sanket.waghmare\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565333333333333\n",
      "0.7552\n",
      "0.7905670633025594\n",
      "0.7861771030815436\n",
      "0.7562666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=2.783)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_valid, y_valid))\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "lr_pred =clf.predict_proba(x_train)[:, 1]\n",
    "score = roc_auc_score(y_train, lr_pred)\n",
    "print(score)\n",
    "\n",
    "valid_pred =clf.predict_proba(x_valid)[:, 1]\n",
    "score = roc_auc_score(y_valid, valid_pred)\n",
    "print(score)\n",
    "\n",
    "print(clf.score(np.array(x),np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanket.waghmare\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7234833333333334\n",
      "1.0\n",
      "0.7325383954042457\n",
      "0.9446966666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100,criterion='entropy')\n",
    "\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_valid, y_valid))\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "train_pred =clf.predict_proba(x_train)[:, 1]\n",
    "score = roc_auc_score(y_train, train_pred)\n",
    "print(score)\n",
    "valid_pred =clf.predict_proba(x_valid)[:, 1]\n",
    "score = roc_auc_score(y_valid, valid_pred)\n",
    "print(score)\n",
    "\n",
    "print(clf.score(np.array(x),np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../test.csv')\n",
    "\n",
    "pred =clf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'target': pred})\n",
    "submission.to_csv('submission7.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
