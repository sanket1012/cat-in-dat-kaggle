{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train = pd.DataFrame()\n",
    "df_train = pd.read_csv('../train.csv')\n",
    "df_test = pd.DataFrame()\n",
    "df_test = pd.read_csv('../test.csv')\n",
    "\n",
    "df_train.drop(['id'], axis=1,inplace=True)\n",
    "df_test.drop(['id'], axis=1,inplace=True)\n",
    "\n",
    "df_train['bin_3'] = (df_train['bin_3'] =='T').astype(int)\n",
    "df_train['bin_4'] = (df_train['bin_4'] =='Y').astype(int)\n",
    "\n",
    "df_test['bin_3'] = (df_test['bin_3'] =='T').astype(int)\n",
    "df_test['bin_4'] = (df_test['bin_4'] =='Y').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Boiling Hot', 'Cold', 'Freezing', 'Hot', 'Lava Hot', 'Warm'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_test['ord_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in nom_0 = 3\n",
      "Number of classes in nom_1 = 6\n",
      "Number of classes in nom_2 = 6\n",
      "Number of classes in nom_3 = 6\n",
      "Number of classes in nom_4 = 4\n",
      "Number of classes in nom_5 = 222\n",
      "Number of classes in nom_6 = 522\n",
      "Number of classes in nom_7 = 1220\n",
      "Number of classes in nom_8 = 2215\n",
      "Number of classes in nom_9 = 11981\n",
      "Number of classes in ord_0 = 3\n",
      "Number of classes in ord_1 = 5\n",
      "Number of classes in ord_2 = 6\n",
      "Number of classes in ord_3 = 15\n",
      "Number of classes in ord_4 = 26\n",
      "Number of classes in ord_5 = 192\n",
      "Number of classes in day = 7\n",
      "Number of classes in month = 12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "def one_hot(train_df,test_df,columns):\n",
    "    \n",
    "    for i,column in enumerate(columns):\n",
    "        Xtrain = train_df[str(column)].T\n",
    "        Xtest = test_df[str(column)].T\n",
    "        \n",
    "        # train_df\n",
    "        lb=LabelBinarizer()\n",
    "        lb.fit(Xtrain)\n",
    "        X_classes = len(lb.classes_)\n",
    "        Xenc = lb.transform(Xtrain)\n",
    "        Xtrain_enc = pd.DataFrame(data = Xenc, columns = lb.classes_)\n",
    "        train_df.drop([str(column)], axis =1, inplace=True)\n",
    "        \n",
    "        # test_df\n",
    "        Xenc = lb.transform(Xtest)\n",
    "        Xtest_enc = pd.DataFrame(data = Xenc, columns = lb.classes_)\n",
    "        test_df.drop([str(column)], axis =1, inplace=True)\n",
    "        \n",
    "        print('Number of classes in '+str(column)+ ' = '+ str(X_classes))\n",
    "        train_df = pd.concat((train_df,Xtrain_enc),axis=1)\n",
    "        test_df = pd.concat((test_df,Xtest_enc),axis=1) \n",
    "    return train_df,test_df\n",
    "\n",
    "train_df , test_df = one_hot(df_train,df_test,['nom_0','nom_1','nom_2','nom_3','nom_4','nom_5','nom_6','nom_7','nom_8','nom_9','ord_0','ord_1','ord_2','ord_3','ord_4','ord_5','day','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin_0=2\n",
      "bin_1=2\n",
      "bin_2=2\n",
      "bin_3=2\n",
      "bin_4=2\n",
      "nom_1=6\n",
      "nom_2=6\n",
      "nom_3=6\n",
      "nom_4=4\n",
      "nom_5=222\n",
      "nom_6=522\n",
      "nom_7=1220\n",
      "nom_8=2215\n",
      "ord_0=3\n",
      "ord_1=5\n",
      "ord_2=6\n",
      "ord_3=15\n",
      "ord_4=26\n",
      "ord_5=192\n",
      "day=7\n",
      "month=12\n",
      "target=2\n"
     ]
    }
   ],
   "source": [
    "for k, v in df_train.nunique().to_dict().items():\n",
    "    print('{}={}'.format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 2260)\n",
      "(300000, 1)\n",
      "(240000, 2260)\n",
      "(60000, 1)\n",
      "(200000, 2260)\n"
     ]
    }
   ],
   "source": [
    "x=train_df.drop(['target'], axis=1)\n",
    "y=train_df[['target']].copy()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "x_test = np.array(test_df)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1108 08:33:22.288170 12364 deprecation.py:506] From C:\\Users\\sanket.waghmare\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 512)               145920    \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 391,137\n",
      "Trainable params: 391,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 240000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "240000/240000 [==============================] - 20s 83us/step - loss: 0.5375 - acc: 0.7328 - val_loss: 0.5278 - val_acc: 0.7377\n",
      "Epoch 2/100\n",
      "240000/240000 [==============================] - 17s 72us/step - loss: 0.5260 - acc: 0.7401 - val_loss: 0.5298 - val_acc: 0.7378\n",
      "Epoch 3/100\n",
      "240000/240000 [==============================] - 18s 76us/step - loss: 0.5210 - acc: 0.7427 - val_loss: 0.5405 - val_acc: 0.7356\n",
      "Epoch 4/100\n",
      "240000/240000 [==============================] - 19s 78us/step - loss: 0.5147 - acc: 0.7468 - val_loss: 0.5339 - val_acc: 0.7342\n",
      "Epoch 5/100\n",
      "240000/240000 [==============================] - 18s 74us/step - loss: 0.5047 - acc: 0.7538 - val_loss: 0.5442 - val_acc: 0.7299\n",
      "Epoch 6/100\n",
      "240000/240000 [==============================] - 18s 76us/step - loss: 0.4898 - acc: 0.7623 - val_loss: 0.5443 - val_acc: 0.7272\n",
      "Epoch 7/100\n",
      "240000/240000 [==============================] - 19s 81us/step - loss: 0.4711 - acc: 0.7757 - val_loss: 0.5625 - val_acc: 0.7090\n",
      "Epoch 8/100\n",
      " 69120/240000 [=======>......................] - ETA: 12s - loss: 0.4368 - acc: 0.7990"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ad2f4b52bfe4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_dim=296))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=100, batch_size=256, validation_data=(x_valid,y_valid), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x=train_df.drop(['target'], axis=1)\n",
    "# y=train_df[['target']].copy()\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# x = x.to_numpy()\n",
    "\n",
    "# x.astype('int32').dtypes\n",
    "\n",
    "# x_train = np.array(x[:int(300000*0.8)])\n",
    "# y_train = np.array(y[:int(300000*0.8)])\n",
    "# x_valid = np.array(x[int(300000*0.8):])\n",
    "# y_valid = np.array(y[int(300000*0.8):])\n",
    "# print(x_train.shape)\n",
    "# print(y_valid.shape)\n",
    "\n",
    "# x_test = np.array(test_df)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 16457)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin.swaghmare\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (240000, 16456) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c972d066676b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.783\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1532\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (240000, 16456) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=2.783)\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_valid, y_valid))\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "lr_pred =clf.predict_proba(x_train)[:, 1]\n",
    "score = roc_auc_score(y_train, lr_pred)\n",
    "print(score)\n",
    "\n",
    "valid_pred =clf.predict_proba(x_valid)[:, 1]\n",
    "score = roc_auc_score(y_valid, valid_pred)\n",
    "print(score)\n",
    "\n",
    "print(clf.score(np.array(x),np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanket.waghmare\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7234833333333334\n",
      "1.0\n",
      "0.7325383954042457\n",
      "0.9446966666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100,criterion='entropy')\n",
    "\n",
    "clf = clf.fit(x_train, y_train)\n",
    "print(clf.score(x_train, y_train))\n",
    "print(clf.score(x_valid, y_valid))\n",
    "\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "train_pred =clf.predict_proba(x_train)[:, 1]\n",
    "score = roc_auc_score(y_train, train_pred)\n",
    "print(score)\n",
    "valid_pred =clf.predict_proba(x_valid)[:, 1]\n",
    "score = roc_auc_score(y_valid, valid_pred)\n",
    "print(score)\n",
    "\n",
    "print(clf.score(np.array(x),np.array(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../test.csv')\n",
    "\n",
    "pred =clf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'target': pred})\n",
    "submission.to_csv('submission10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin.swaghmare\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\admin.swaghmare\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../test.csv')\n",
    "\n",
    "clf = LogisticRegression(C=2.783)\n",
    "clf = clf.fit(x, y)\n",
    "\n",
    "pred =clf.predict_proba(x_test)[:, 1]\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'target': pred})\n",
    "submission.to_csv('submission11.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16457)\n",
      "1000\n",
      "(1000, 16457)\n",
      "2000\n",
      "(1000, 16457)\n",
      "3000\n",
      "(1000, 16457)\n",
      "4000\n",
      "(1000, 16457)\n",
      "5000\n",
      "(1000, 16457)\n",
      "6000\n",
      "(1000, 16457)\n",
      "7000\n",
      "(1000, 16457)\n",
      "8000\n",
      "(1000, 16457)\n",
      "9000\n",
      "(1000, 16457)\n",
      "10000\n",
      "(1000, 16457)\n",
      "11000\n",
      "(1000, 16457)\n",
      "12000\n",
      "(1000, 16457)\n",
      "13000\n",
      "(1000, 16457)\n",
      "14000\n",
      "(1000, 16457)\n",
      "15000\n",
      "(1000, 16457)\n",
      "16000\n",
      "(1000, 16457)\n",
      "17000\n",
      "(1000, 16457)\n",
      "18000\n",
      "(1000, 16457)\n",
      "19000\n",
      "(1000, 16457)\n",
      "20000\n",
      "(1000, 16457)\n",
      "21000\n",
      "(1000, 16457)\n",
      "22000\n",
      "(1000, 16457)\n",
      "23000\n",
      "(1000, 16457)\n",
      "24000\n",
      "(1000, 16457)\n",
      "25000\n",
      "(1000, 16457)\n",
      "26000\n",
      "(1000, 16457)\n",
      "27000\n",
      "(1000, 16457)\n",
      "28000\n",
      "(1000, 16457)\n",
      "29000\n",
      "(1000, 16457)\n",
      "30000\n",
      "(1000, 16457)\n",
      "31000\n",
      "(1000, 16457)\n",
      "32000\n",
      "(1000, 16457)\n",
      "33000\n",
      "(1000, 16457)\n",
      "34000\n",
      "(1000, 16457)\n",
      "35000\n",
      "(1000, 16457)\n",
      "36000\n",
      "(1000, 16457)\n",
      "37000\n",
      "(1000, 16457)\n",
      "38000\n",
      "(1000, 16457)\n",
      "39000\n",
      "(1000, 16457)\n",
      "40000\n",
      "(1000, 16457)\n",
      "41000\n",
      "(1000, 16457)\n",
      "42000\n",
      "(1000, 16457)\n",
      "43000\n",
      "(1000, 16457)\n",
      "44000\n",
      "(1000, 16457)\n",
      "45000\n",
      "(1000, 16457)\n",
      "46000\n",
      "(1000, 16457)\n",
      "47000\n",
      "(1000, 16457)\n",
      "48000\n",
      "(1000, 16457)\n",
      "49000\n",
      "(1000, 16457)\n",
      "50000\n",
      "(1000, 16457)\n",
      "51000\n",
      "(1000, 16457)\n",
      "52000\n",
      "(1000, 16457)\n",
      "53000\n",
      "(1000, 16457)\n",
      "54000\n",
      "(1000, 16457)\n",
      "55000\n",
      "(1000, 16457)\n",
      "56000\n",
      "(1000, 16457)\n",
      "57000\n",
      "(1000, 16457)\n",
      "58000\n",
      "(1000, 16457)\n",
      "59000\n",
      "(1000, 16457)\n",
      "60000\n",
      "(1000, 16457)\n",
      "61000\n",
      "(1000, 16457)\n",
      "62000\n",
      "(1000, 16457)\n",
      "63000\n",
      "(1000, 16457)\n",
      "64000\n",
      "(1000, 16457)\n",
      "65000\n",
      "(1000, 16457)\n",
      "66000\n",
      "(1000, 16457)\n",
      "67000\n",
      "(1000, 16457)\n",
      "68000\n",
      "(1000, 16457)\n",
      "69000\n",
      "(1000, 16457)\n",
      "70000\n",
      "(1000, 16457)\n",
      "71000\n",
      "(1000, 16457)\n",
      "72000\n",
      "(1000, 16457)\n",
      "73000\n",
      "(1000, 16457)\n",
      "74000\n",
      "(1000, 16457)\n",
      "75000\n",
      "(1000, 16457)\n",
      "76000\n",
      "(1000, 16457)\n",
      "77000\n",
      "(1000, 16457)\n",
      "78000\n",
      "(1000, 16457)\n",
      "79000\n",
      "(1000, 16457)\n",
      "80000\n",
      "(1000, 16457)\n",
      "81000\n",
      "(1000, 16457)\n",
      "82000\n",
      "(1000, 16457)\n",
      "83000\n",
      "(1000, 16457)\n",
      "84000\n",
      "(1000, 16457)\n",
      "85000\n",
      "(1000, 16457)\n",
      "86000\n",
      "(1000, 16457)\n",
      "87000\n",
      "(1000, 16457)\n",
      "88000\n",
      "(1000, 16457)\n",
      "89000\n",
      "(1000, 16457)\n",
      "90000\n",
      "(1000, 16457)\n",
      "91000\n",
      "(1000, 16457)\n",
      "92000\n",
      "(1000, 16457)\n",
      "93000\n",
      "(1000, 16457)\n",
      "94000\n",
      "(1000, 16457)\n",
      "95000\n",
      "(1000, 16457)\n",
      "96000\n",
      "(1000, 16457)\n",
      "97000\n",
      "(1000, 16457)\n",
      "98000\n",
      "(1000, 16457)\n",
      "99000\n",
      "(1000, 16457)\n",
      "100000\n",
      "(1000, 16457)\n",
      "101000\n",
      "(1000, 16457)\n",
      "102000\n",
      "(1000, 16457)\n",
      "103000\n",
      "(1000, 16457)\n",
      "104000\n",
      "(1000, 16457)\n",
      "105000\n",
      "(1000, 16457)\n",
      "106000\n",
      "(1000, 16457)\n",
      "107000\n",
      "(1000, 16457)\n",
      "108000\n",
      "(1000, 16457)\n",
      "109000\n",
      "(1000, 16457)\n",
      "110000\n",
      "(1000, 16457)\n",
      "111000\n",
      "(1000, 16457)\n",
      "112000\n",
      "(1000, 16457)\n",
      "113000\n",
      "(1000, 16457)\n",
      "114000\n",
      "(1000, 16457)\n",
      "115000\n",
      "(1000, 16457)\n",
      "116000\n",
      "(1000, 16457)\n",
      "117000\n",
      "(1000, 16457)\n",
      "118000\n",
      "(1000, 16457)\n",
      "119000\n",
      "(1000, 16457)\n",
      "120000\n",
      "(1000, 16457)\n",
      "121000\n",
      "(1000, 16457)\n",
      "122000\n",
      "(1000, 16457)\n",
      "123000\n",
      "(1000, 16457)\n",
      "124000\n",
      "(1000, 16457)\n",
      "125000\n",
      "(1000, 16457)\n",
      "126000\n",
      "(1000, 16457)\n",
      "127000\n",
      "(1000, 16457)\n",
      "128000\n",
      "(1000, 16457)\n",
      "129000\n",
      "(1000, 16457)\n",
      "130000\n",
      "(1000, 16457)\n",
      "131000\n",
      "(1000, 16457)\n",
      "132000\n",
      "(1000, 16457)\n",
      "133000\n",
      "(1000, 16457)\n",
      "134000\n",
      "(1000, 16457)\n",
      "135000\n",
      "(1000, 16457)\n",
      "136000\n",
      "(1000, 16457)\n",
      "137000\n",
      "(1000, 16457)\n",
      "138000\n",
      "(1000, 16457)\n",
      "139000\n",
      "(1000, 16457)\n",
      "140000\n",
      "(1000, 16457)\n",
      "141000\n",
      "(1000, 16457)\n",
      "142000\n",
      "(1000, 16457)\n",
      "143000\n",
      "(1000, 16457)\n",
      "144000\n",
      "(1000, 16457)\n",
      "145000\n",
      "(1000, 16457)\n",
      "146000\n",
      "(1000, 16457)\n",
      "147000\n",
      "(1000, 16457)\n",
      "148000\n",
      "(1000, 16457)\n",
      "149000\n",
      "(1000, 16457)\n",
      "150000\n",
      "(1000, 16457)\n",
      "151000\n",
      "(1000, 16457)\n",
      "152000\n",
      "(1000, 16457)\n",
      "153000\n",
      "(1000, 16457)\n",
      "154000\n",
      "(1000, 16457)\n",
      "155000\n",
      "(1000, 16457)\n",
      "156000\n",
      "(1000, 16457)\n",
      "157000\n",
      "(1000, 16457)\n",
      "158000\n",
      "(1000, 16457)\n",
      "159000\n",
      "(1000, 16457)\n",
      "160000\n",
      "(1000, 16457)\n",
      "161000\n",
      "(1000, 16457)\n",
      "162000\n",
      "(1000, 16457)\n",
      "163000\n",
      "(1000, 16457)\n",
      "164000\n",
      "(1000, 16457)\n",
      "165000\n",
      "(1000, 16457)\n",
      "166000\n",
      "(1000, 16457)\n",
      "167000\n",
      "(1000, 16457)\n",
      "168000\n",
      "(1000, 16457)\n",
      "169000\n",
      "(1000, 16457)\n",
      "170000\n",
      "(1000, 16457)\n",
      "171000\n",
      "(1000, 16457)\n",
      "172000\n",
      "(1000, 16457)\n",
      "173000\n",
      "(1000, 16457)\n",
      "174000\n",
      "(1000, 16457)\n",
      "175000\n",
      "(1000, 16457)\n",
      "176000\n",
      "(1000, 16457)\n",
      "177000\n",
      "(1000, 16457)\n",
      "178000\n",
      "(1000, 16457)\n",
      "179000\n",
      "(1000, 16457)\n",
      "180000\n",
      "(1000, 16457)\n",
      "181000\n",
      "(1000, 16457)\n",
      "182000\n",
      "(1000, 16457)\n",
      "183000\n",
      "(1000, 16457)\n",
      "184000\n",
      "(1000, 16457)\n",
      "185000\n",
      "(1000, 16457)\n",
      "186000\n",
      "(1000, 16457)\n",
      "187000\n",
      "(1000, 16457)\n",
      "188000\n",
      "(1000, 16457)\n",
      "189000\n",
      "(1000, 16457)\n",
      "190000\n",
      "(1000, 16457)\n",
      "191000\n",
      "(1000, 16457)\n",
      "192000\n",
      "(1000, 16457)\n",
      "193000\n",
      "(1000, 16457)\n",
      "194000\n",
      "(1000, 16457)\n",
      "195000\n",
      "(1000, 16457)\n",
      "196000\n",
      "(1000, 16457)\n",
      "197000\n",
      "(1000, 16457)\n",
      "198000\n",
      "(1000, 16457)\n",
      "199000\n",
      "(1000, 16457)\n",
      "200000\n",
      "(1000, 16457)\n",
      "201000\n",
      "(1000, 16457)\n",
      "202000\n",
      "(1000, 16457)\n",
      "203000\n",
      "(1000, 16457)\n",
      "204000\n",
      "(1000, 16457)\n",
      "205000\n",
      "(1000, 16457)\n",
      "206000\n",
      "(1000, 16457)\n",
      "207000\n",
      "(1000, 16457)\n",
      "208000\n",
      "(1000, 16457)\n",
      "209000\n",
      "(1000, 16457)\n",
      "210000\n",
      "(1000, 16457)\n",
      "211000\n",
      "(1000, 16457)\n",
      "212000\n",
      "(1000, 16457)\n",
      "213000\n",
      "(1000, 16457)\n",
      "214000\n",
      "(1000, 16457)\n",
      "215000\n",
      "(1000, 16457)\n",
      "216000\n",
      "(1000, 16457)\n",
      "217000\n",
      "(1000, 16457)\n",
      "218000\n",
      "(1000, 16457)\n",
      "219000\n",
      "(1000, 16457)\n",
      "220000\n",
      "(1000, 16457)\n",
      "221000\n",
      "(1000, 16457)\n",
      "222000\n",
      "(1000, 16457)\n",
      "223000\n",
      "(1000, 16457)\n",
      "224000\n",
      "(1000, 16457)\n",
      "225000\n",
      "(1000, 16457)\n",
      "226000\n",
      "(1000, 16457)\n",
      "227000\n",
      "(1000, 16457)\n",
      "228000\n",
      "(1000, 16457)\n",
      "229000\n",
      "(1000, 16457)\n",
      "230000\n",
      "(1000, 16457)\n",
      "231000\n",
      "(1000, 16457)\n",
      "232000\n",
      "(1000, 16457)\n",
      "233000\n",
      "(1000, 16457)\n",
      "234000\n",
      "(1000, 16457)\n",
      "235000\n",
      "(1000, 16457)\n",
      "236000\n",
      "(1000, 16457)\n",
      "237000\n",
      "(1000, 16457)\n",
      "238000\n",
      "(1000, 16457)\n",
      "239000\n",
      "(1000, 16457)\n",
      "240000\n",
      "(1000, 16457)\n",
      "241000\n",
      "(1000, 16457)\n",
      "242000\n",
      "(1000, 16457)\n",
      "243000\n",
      "(288, 16457)\n",
      "244000\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for chunk in pd.read_csv('./train_df.csv', chunksize=1000):\n",
    "    print(chunk.shape)\n",
    "    sum = sum+1000\n",
    "    print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
